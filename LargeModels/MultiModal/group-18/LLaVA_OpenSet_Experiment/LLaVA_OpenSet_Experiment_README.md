# ðŸ§  LLaVA å¼€æ”¾é›†è¯†åˆ«å®žéªŒ (Open-Set Recognition with LLaVA)

> äººå·¥æ™ºèƒ½åŽŸç†ä¸Žåº”ç”¨è¯¾ç¨‹ Â· ç¬¬ 18 ç»„ Â· é™†æ—­

æœ¬å®žéªŒåŸºäºŽ [LLaVA (Large Language and Vision Assistant)](https://github.com/haotian-liu/LLaVA)ï¼Œæ—¨åœ¨æŽ¢ç´¢å¤šæ¨¡æ€å¤§æ¨¡åž‹åœ¨ **å¼€æ”¾é›†åœºæ™¯ä¸‹çš„è¯†åˆ«èƒ½åŠ›**ï¼Œå³åŒºåˆ†ã€Œå·²çŸ¥ç±»ã€ä¸Žã€ŒæœªçŸ¥ç±»ï¼ˆç§æœ‰åœºæ™¯ï¼‰ã€çš„èƒ½åŠ›ã€‚

---

## ðŸ§© å®žéªŒæ•´ä½“æµç¨‹

### **1ï¸âƒ£ çŽ¯å¢ƒå‡†å¤‡**

```bash
# åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
conda create -n llava python=3.10
conda activate llava

# å®‰è£…ä¾èµ–
pip install -e .
```

> âš ï¸ å»ºè®®è¿è¡Œç›®å½•ä¸ºï¼š
> `/media/e509/æœ¬åœ°ç£ç›˜1/lx_LLaVA/LLaVA`

---

### **2ï¸âƒ£ ä¸‹è½½æ¨¡åž‹æƒé‡ä¸Žç¼–ç å™¨**

å®žéªŒéœ€è¦ä¸¤ä¸ªä¸»è¦æ¨¡åž‹ï¼š

| æ¨¡åž‹åç§°                  | è¯´æ˜Ž             | ä¸‹è½½åŽç›®å½•                          |
| --------------------- | -------------- | ------------------------------ |
| **LLaVA v1.5-7B**     | å¤šæ¨¡æ€å¤§æ¨¡åž‹ä¸»ä½“       | `./llava-v1.5-7b`              |
| **CLIP ViT-L/14-336** | è§†è§‰ç¼–ç å™¨ï¼Œç”¨äºŽå›¾åƒç‰¹å¾æå– | `./clip-vit-large-patch14-336` |

```bash
# ä¸‹è½½ LLaVA æ¨¡åž‹
huggingface-cli download liuhaotian/llava-v1.5-7b --local-dir ./llava-v1.5-7b

# ä¸‹è½½ CLIP è§†è§‰ç¼–ç å™¨
huggingface-cli download openai/clip-vit-large-patch14-336 --local-dir ./clip-vit-large-patch14-336
```

---

### **3ï¸âƒ£ å•å›¾éªŒè¯ï¼ˆç¡®è®¤çŽ¯å¢ƒæ­£å¸¸ï¼‰**

```bash
python -m llava.serve.cli   --model-path "./llava-v1.5-7b"   --image-file "/media/e509/æœ¬åœ°ç£ç›˜1/lx_LLaVA/LLaVA/1.JPG"   --load-4bit
```

> è‹¥æ¨¡åž‹èƒ½è¾“å‡ºç»“æžœè¯´æ˜ŽåŠ è½½æ­£å¸¸ã€‚

---

### **4ï¸âƒ£ æ•°æ®å‡†å¤‡**

#### (1) COCO å·²çŸ¥ç±»æ•°æ®

è·¯å¾„ï¼š

```
/media/e509/æœ¬åœ°ç£ç›˜1/lx_LLaVA/data/COCO2017/train2017
```

è¿è¡Œæ•°æ®æå–è„šæœ¬ï¼š

```bash
python make_known_from_coco.py
```

è¾“å‡ºæ–‡ä»¶åŒ…æ‹¬ï¼š

| æ–‡ä»¶å                      | è¯´æ˜Ž           |
| ------------------------ | ------------ |
| `data/known_images/`     | ç­›é€‰å‡ºçš„ä¸»ç‰©ä½“æ˜Žæ˜¾çš„å›¾ç‰‡ |
| `data/known_meta.csv`    | æ¯å¼ å›¾ç‰‡çš„è·¯å¾„ä¸Žæ ‡ç­¾   |
| `data/known_classes.txt` | 12 ä¸ªå·²çŸ¥ç±»åˆ«åˆ—è¡¨   |

---

#### (2) ç§æœ‰ç±»æ•°æ®é‡‡é›†

é‡‡é›†ä½ è‡ªå·±çš„ **æœªçŸ¥åœºæ™¯æ•°æ®**ï¼ŒåŒ…æ‹¬ï¼š

- å®¿èˆæ•´ä½“åœºæ™¯ (`dorm_room`)
- æ•™å®¤æ•´ä½“åœºæ™¯ (`classroom_overall`)
- æ¥¼é“å…¬å‘Šæ /æµ·æŠ¥å¢™ (`notice_board`)

æ”¾å…¥è·¯å¾„ï¼š

```
LLaVA/data/private_images/
```

æ‰‹åŠ¨åˆ›å»ºä¸€ä¸ªæ ‡ç­¾æ–‡ä»¶ `data/private_labels.csv`ï¼š

```csv
filename,label
1.png,dorm_room
10.png,dorm_room
11.png,classroom_overall
12.png,classroom_overall
13.png,office_desk
14.png,notice_board
```

---

### **5ï¸âƒ£ æ‰¹é‡é—®ç­”æŽ¨ç†**

ç»Ÿä¸€è‹±æ–‡æ¨¡æ¿ï¼ˆé¿å…è¯­è¨€åå·®ï¼‰ï¼š

```
You are a vision classifier. Look at the image and determine the single main object.
If it clearly belongs to one of these categories:
person, dog, cat, car, bus, bicycle, train, truck, airplane, boat, tv, laptop,
then answer with exactly that one word (for example: 'dog').
If it does not fit any of those categories, answer with a short English noun phrase 
describing the main object or scene, such as 'dorm room', 'classroom', 'office desk', or 
'notice board'. Do not use full sentences and do not add any extra words.
```

è¿è¡Œæ‰¹é‡æŽ¨ç†ï¼š

```bash
python run_llava_batch.py
```

è¾“å‡ºæ–‡ä»¶ï¼š

| æ–‡ä»¶å                             | å«ä¹‰           |
| ------------------------------- | ------------ |
| `results/results_known.jsonl`   | COCO å·²çŸ¥ç±»é¢„æµ‹ç»“æžœ |
| `results/results_private.jsonl` | ç§æœ‰ç±»é¢„æµ‹ç»“æžœ      |

---

### **6ï¸âƒ£ å¼€æ”¾é›†è¯„ä¼°**

è¿è¡Œè¯„ä¼°è„šæœ¬ï¼š

```bash
python open_set_eval_simple.py
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
==== Split: known ====
Total samples: 240
Closed-set accuracy: 75.4%
Predicted as Known: 85.0%
Accuracy among Known: 88.7%

==== Split: private ====
Total samples: 30
Predicted as Unknown: 86.7%
```

> - â€œClosed-set accuracyâ€ è¡¨ç¤ºæ¨¡åž‹åœ¨å·²çŸ¥ç±»ä¸Šçš„åˆ†ç±»ç²¾åº¦  
> - â€œPredicted as Unknownâ€ è¡¨ç¤ºæ¨¡åž‹èƒ½æ­£ç¡®æ‹’ç»æœªçŸ¥ç±»çš„æ¯”ä¾‹ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰

---

### **7ï¸âƒ£ ç»“æžœåˆ†æžä¸Žæ€»ç»“**

- æ¨¡åž‹ï¼š`LLaVA v1.5-7B`
- è§†è§‰ç¼–ç å™¨ï¼š`CLIP ViT-L/14-336`
- å·²çŸ¥ç±»ï¼šCOCO12ç±» (person, dog, cat, car, bus, bicycle, train, truck, airplane, boat, tv, laptop)
- ç§æœ‰ç±»ï¼š3ç±»çœŸå®žåœºæ™¯ï¼ˆå®¿èˆã€æ•™å®¤ã€å…¬å‘Šæ ï¼‰
- é—®é¢˜æ¨¡æ¿ï¼šç»Ÿä¸€è‹±æ–‡é—®é¢˜ï¼Œé¿å…å¤šè¯­è¨€è¯­ä¹‰åå·®
- è¯„ä¼°æ–¹æ³•ï¼š
  -åŸºäºŽå…³é”®è¯åŒ¹é…ï¼ˆknown vs unknownï¼‰

---

ðŸ“ **æœ€ç»ˆç”Ÿæˆæ–‡ä»¶ç»“æž„ç¤ºä¾‹**

```
LLaVA/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ known_images/
â”‚   â”œâ”€â”€ private_images/
â”‚   â”œâ”€â”€ known_meta.csv
â”‚   â”œâ”€â”€ known_classes.txt
â”‚   â”œâ”€â”€ private_labels.csv
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ results_known.jsonl
â”‚   â”œâ”€â”€ results_private.jsonl
â”œâ”€â”€ make_known_from_coco.py
â”œâ”€â”€ run_llava_batch.py
â”œâ”€â”€ open_set_eval_simple.py
â””â”€â”€ README.md
```

---

---

### ä½œè€…ç½²å

**SY2503513-é™†æ—­**
å¦‚æœ‰é—®é¢˜è¯·è”ç³»ï¼šsdluxu2003@163.com

---

### **8ï¸âƒ£ å¼•ç”¨è¯´æ˜Ž**

æœ¬å®žéªŒåŸºäºŽä»¥ä¸‹é¡¹ç›®æ‰©å±•å®žçŽ°ï¼š

> [LLaVA: Large Language and Vision Assistant (Liu et al., 2023)](https://github.com/haotian-liu/LLaVA)

è¯·åœ¨è®ºæ–‡æˆ–æŠ¥å‘Šä¸­å¼•ç”¨åŽŸå§‹å·¥ä½œï¼š

```bibtex
@article{liu2023llava,
  title={Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}
```
